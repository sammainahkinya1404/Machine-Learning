{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0wkp5WfopB/aNNToHqaUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sammainahkinya1404/Machine-Learning/blob/main/CS5920_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cN3biczKYbi",
        "outputId": "4bd74808-bb96-4eba-b572-3cdabf5fcbba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycaret==2.0\n",
            "  Downloading pycaret-2.0-py3-none-any.whl (255 kB)\n",
            "\u001b[K     |████████████████████████████████| 255 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imbalanced-learn in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (0.8.1)\n",
            "Collecting pyod\n",
            "  Downloading pyod-1.0.6.tar.gz (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 49.3 MB/s \n",
            "\u001b[?25hCollecting catboost\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (1.0.2)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (0.17.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (1.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (3.7)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (5.5.0)\n",
            "Collecting kmodes>=0.10.1\n",
            "  Downloading kmodes-0.12.2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting DateTime>=4.3\n",
            "  Downloading DateTime-4.7-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 338 kB/s \n",
            "\u001b[?25hRequirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (7.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (3.2.2)\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (3.4.3)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (0.90)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (0.14.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (3.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (1.3.5)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (7.7.1)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (1.5)\n",
            "Collecting pandas-profiling>=2.3.0\n",
            "  Downloading pandas_profiling-3.5.0-py2.py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 55.7 MB/s \n",
            "\u001b[?25hCollecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 49.9 MB/s \n",
            "\u001b[?25hCollecting mlflow\n",
            "  Downloading mlflow-2.0.1-py3-none-any.whl (16.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.5 MB 44.3 MB/s \n",
            "\u001b[?25hCollecting datefinder>=0.7.0\n",
            "  Downloading datefinder-0.7.3-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 61.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (1.21.6)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (0.15.3)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (1.8.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from pycaret==2.0) (0.11.2)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret==2.0) (57.4.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret==2.0) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret==2.0) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.8/dist-packages (from datefinder>=0.7.0->pycaret==2.0) (2.8.2)\n",
            "Requirement already satisfied: regex>=2017.02.08 in /usr/local/lib/python3.8/dist-packages (from datefinder>=0.7.0->pycaret==2.0) (2022.6.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from datefinder>=0.7.0->pycaret==2.0) (2022.6)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-5.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (261 kB)\n",
            "\u001b[K     |████████████████████████████████| 261 kB 71.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret==2.0) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret==2.0) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret==2.0) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 74.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret==2.0) (5.6.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret==2.0) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret==2.0) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret==2.0) (2.6.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret==2.0) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret==2.0) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret==2.0) (3.0.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret==2.0) (3.6.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret==2.0) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret==2.0) (6.0.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->pycaret==2.0) (0.8.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.8/dist-packages (from kmodes>=0.10.1->pycaret==2.0) (1.7.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=2.3.1->pycaret==2.0) (0.38.4)\n",
            "Collecting visions[type_image_path]==0.7.5\n",
            "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 58.6 MB/s \n",
            "\u001b[?25hCollecting statsmodels<0.14,>=0.13.2\n",
            "  Downloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 45.9 MB/s \n",
            "\u001b[?25hCollecting multimethod<1.10,>=1.4\n",
            "  Downloading multimethod-1.9-py3-none-any.whl (10 kB)\n",
            "Collecting requests<2.29,>=2.24.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic<1.11,>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas-profiling>=2.3.0->pycaret==2.0) (1.10.2)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.8/dist-packages (from pandas-profiling>=2.3.0->pycaret==2.0) (2.11.3)\n",
            "Collecting phik<0.13,>=0.11.1\n",
            "  Downloading phik-0.12.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n",
            "\u001b[K     |████████████████████████████████| 679 kB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<4.65,>=4.48.2 in /usr/local/lib/python3.8/dist-packages (from pandas-profiling>=2.3.0->pycaret==2.0) (4.64.1)\n",
            "Collecting htmlmin==0.1.12\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "Collecting typeguard<2.14,>=2.13.2\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from pandas-profiling>=2.3.0->pycaret==2.0) (6.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.8/dist-packages (from visions[type_image_path]==0.7.5->pandas-profiling>=2.3.0->pycaret==2.0) (22.1.0)\n",
            "Collecting tangled-up-in-unicode>=0.0.4\n",
            "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.8/dist-packages (from visions[type_image_path]==0.7.5->pandas-profiling>=2.3.0->pycaret==2.0) (2.8.8)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[K     |████████████████████████████████| 296 kB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from visions[type_image_path]==0.7.5->pandas-profiling>=2.3.0->pycaret==2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2<3.2,>=2.11.1->pandas-profiling>=2.3.0->pycaret==2.0) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret==2.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret==2.0) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret==2.0) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=4.4.1->pycaret==2.0) (8.1.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->pycaret==2.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<1.11,>=1.8.1->pandas-profiling>=2.3.0->pycaret==2.0) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<2.29,>=2.24.0->pandas-profiling>=2.3.0->pycaret==2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<2.29,>=2.24.0->pandas-profiling>=2.3.0->pycaret==2.0) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<2.29,>=2.24.0->pandas-profiling>=2.3.0->pycaret==2.0) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<2.29,>=2.24.0->pandas-profiling>=2.3.0->pycaret==2.0) (2022.9.24)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.23->pycaret==2.0) (3.1.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.8/dist-packages (from statsmodels<0.14,>=0.13.2->pandas-profiling>=2.3.0->pycaret==2.0) (21.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels<0.14,>=0.13.2->pandas-profiling>=2.3.0->pycaret==2.0) (0.5.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (5.7.16)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (23.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (5.1.0)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (0.13.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (5.7.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (1.8.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (0.15.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (2.5.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (0.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (5.0.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (2.16.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (5.10.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (3.11.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.0) (0.5.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost->pycaret==2.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim->pycaret==2.0) (5.2.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.8/dist-packages (from imagehash->visions[type_image_path]==0.7.5->pandas-profiling>=2.3.0->pycaret==2.0) (1.4.1)\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret==2.0) (3.4.1)\n",
            "Collecting databricks-cli<1,>=0.8.7\n",
            "  Downloading databricks-cli-0.17.4.tar.gz (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 459 kB/s \n",
            "\u001b[?25hCollecting gunicorn<21\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 353 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<11,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret==2.0) (9.0.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret==2.0) (3.19.6)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret==2.0) (7.1.2)\n",
            "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret==2.0) (1.4.44)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret==2.0) (0.4.3)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret==2.0) (1.5.0)\n",
            "Collecting docker<7,>=4.0.0\n",
            "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 63.9 MB/s \n",
            "\u001b[?25hCollecting alembic<2\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 62.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret==2.0) (1.1.4)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<6,>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret==2.0) (4.13.0)\n",
            "Collecting shap<1,>=0.40\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[K     |████████████████████████████████| 575 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting querystring-parser<2\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->pycaret==2.0) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->pycaret==2.0) (0.8.10)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 78.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->pycaret==2.0) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->pycaret==2.0) (1.1.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow->pycaret==2.0) (0.56.4)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow->pycaret==2.0) (2.0.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap<1,>=0.40->mlflow->pycaret==2.0) (0.39.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from pyLDAvis->pycaret==2.0) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.8/dist-packages (from pyLDAvis->pycaret==2.0) (2.8.4)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (8.1.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (3.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (1.0.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (3.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (2.4.5)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (1.0.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (0.10.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy->pycaret==2.0) (0.10.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->pycaret==2.0) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy->pycaret==2.0) (0.7.9)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 77.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: htmlmin, databricks-cli, pyLDAvis, pyod, sklearn, umap-learn, pynndescent\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=130871359950da57ced0fdcb0555ba0e07448687918d537f798cac59f7b92e2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/14/6e/4be5bfeeb027f4939a01764b48edd5996acf574b0913fe5243\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.4-py3-none-any.whl size=142894 sha256=043308bb8a46aa137e0ce6d40dac54a1a6c7d0a352c88da8d3057b6012090b4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/7c/6e/4bf2c1748c7ecf994ca951591de81674ed6bf633e1e337d873\n",
            "  Building wheel for pyLDAvis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136898 sha256=7ed5da68dd6653dce5aecf496b2960b107efd339173e1cccd3f6fb1c0fd93592\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/61/ec/9dbe9efc3acf9c4e37ba70fbbcc3f3a0ebd121060aa593181a\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-1.0.6-py3-none-any.whl size=175098 sha256=723adcabf4e90649dedf3e6b2c28fc48ffa6dfba4b76659a0332a223aecb49ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/93/e6/6d40410d9635ecde42d06041a1ba7f2ee7396e036fcf702e73\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=61af5f282b29d515c2361f095d46b5c688976d4645ec302070f8652afb55c448\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=4b133a4c9c2a7339a6d9ef1bc568ee938520df6296af2de3fd4228faa554133f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/3a/67/06a8950e053725912e6a8c42c4a3a241410f6487b8402542ea\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55513 sha256=59c3cf41b04ce81e8c8472fd49164d2095f3ae8c8cf39060c889eef0f83dcfdc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/63/3a/29954bca1a27ba100ed8c27973a78cb71b43dc67aed62e80c3\n",
            "Successfully built htmlmin databricks-cli pyLDAvis pyod sklearn umap-learn pynndescent\n",
            "Installing collected packages: jedi, urllib3, tangled-up-in-unicode, smmap, multimethod, websocket-client, visions, slicer, requests, pyjwt, Mako, imagehash, gitdb, zope.interface, typeguard, statsmodels, sklearn, shap, querystring-parser, pynndescent, phik, htmlmin, gunicorn, gitpython, funcy, docker, databricks-cli, alembic, umap-learn, pyod, pyLDAvis, pandas-profiling, mlflow, lightgbm, kmodes, DateTime, datefinder, catboost, pycaret\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 2.7.1\n",
            "    Uninstalling typeguard-2.7.1:\n",
            "      Successfully uninstalled typeguard-2.7.1\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.12.2\n",
            "    Uninstalling statsmodels-0.12.2:\n",
            "      Successfully uninstalled statsmodels-0.12.2\n",
            "  Attempting uninstall: pandas-profiling\n",
            "    Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed DateTime-4.7 Mako-1.2.4 alembic-1.8.1 catboost-1.1.1 databricks-cli-0.17.4 datefinder-0.7.3 docker-6.0.1 funcy-1.17 gitdb-4.0.10 gitpython-3.1.29 gunicorn-20.1.0 htmlmin-0.1.12 imagehash-4.3.1 jedi-0.18.2 kmodes-0.12.2 lightgbm-3.3.3 mlflow-2.0.1 multimethod-1.9 pandas-profiling-3.5.0 phik-0.12.3 pyLDAvis-3.3.1 pycaret-2.0 pyjwt-2.6.0 pynndescent-0.5.8 pyod-1.0.6 querystring-parser-1.2.4 requests-2.28.1 shap-0.41.0 sklearn-0.0.post1 slicer-0.0.7 smmap-5.0.0 statsmodels-0.13.5 tangled-up-in-unicode-0.2.0 typeguard-2.13.3 umap-learn-0.5.3 urllib3-1.26.13 visions-0.7.5 websocket-client-1.4.2 zope.interface-5.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pycaret==2.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XWIFNjO5Laa8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyCaret is an open-source, low-code machine learning library in Python that allows users to easily train, tune, and deploy machine learning models. It is designed to be user-friendly and make it easy for non-experts to get started with machine learning. PyCaret offers a range of features that make it a powerful tool for building machine learning models, including data preprocessing, model training and tuning, and model deployment. It also provides a range of visualization tools that allow users to better understand and interpret their machine learning models. Overall, PyCaret is a valuable resource for anyone looking to build machine learning models in Python."
      ],
      "metadata": {
        "id": "PrduEca-L9hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mplcyberpunk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTqArn-hR5uV",
        "outputId": "f243c0c4-03d3-44ad-ab4c-9ff2eed4c710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mplcyberpunk\n",
            "  Downloading mplcyberpunk-0.6.0-py3-none-any.whl (6.0 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mplcyberpunk) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mplcyberpunk) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mplcyberpunk) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mplcyberpunk) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mplcyberpunk) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mplcyberpunk) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->mplcyberpunk) (1.15.0)\n",
            "Installing collected packages: mplcyberpunk\n",
            "Successfully installed mplcyberpunk-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing important Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import mplcyberpunk\n",
        "from sklearn.datasets import load_wine\n",
        "plt.style.use(\"cyberpunk\")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "WOer0WR_L_h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Creating The Dataset.\n",
        "# Load the data set into Python using, e.g., load_wine or genfromtxt, as\n",
        "# appropriate. \n",
        "wine=load_wine()\n",
        "# converting wine to dataframe using pandas\n",
        "wineDf = pd.DataFrame(wine['data'],columns = wine['feature_names'])\n",
        "# printing the first five columns of the dataset\n",
        "wineDf.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "LmpH-ifIMq15",
        "outputId": "e02a0d5b-8186-4fae-a07a-f71ccf4795c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "\n",
              "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0        3.06                  0.28             2.29             5.64  1.04   \n",
              "1        2.76                  0.26             1.28             4.38  1.05   \n",
              "2        3.24                  0.30             2.81             5.68  1.03   \n",
              "3        3.49                  0.24             2.18             7.80  0.86   \n",
              "4        2.69                  0.39             1.82             4.32  1.04   \n",
              "\n",
              "   od280/od315_of_diluted_wines  proline  \n",
              "0                          3.92   1065.0  \n",
              "1                          3.40   1050.0  \n",
              "2                          3.17   1185.0  \n",
              "3                          3.45   1480.0  \n",
              "4                          2.93    735.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cdac55e-d305-4c64-bd00-91005ec9dd79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cdac55e-d305-4c64-bd00-91005ec9dd79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cdac55e-d305-4c64-bd00-91005ec9dd79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cdac55e-d305-4c64-bd00-91005ec9dd79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing Statistics on  the \n",
        "wineDf.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "aGN0XsNlO1PD",
        "outputId": "76b5cef5-cae7-4972-f9f6-0d308ffef445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
              "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
              "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
              "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
              "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
              "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
              "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
              "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
              "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
              "\n",
              "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
              "count     178.000000  178.000000            178.000000       178.000000   \n",
              "mean        2.295112    2.029270              0.361854         1.590899   \n",
              "std         0.625851    0.998859              0.124453         0.572359   \n",
              "min         0.980000    0.340000              0.130000         0.410000   \n",
              "25%         1.742500    1.205000              0.270000         1.250000   \n",
              "50%         2.355000    2.135000              0.340000         1.555000   \n",
              "75%         2.800000    2.875000              0.437500         1.950000   \n",
              "max         3.880000    5.080000              0.660000         3.580000   \n",
              "\n",
              "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
              "count       178.000000  178.000000                    178.000000   178.000000  \n",
              "mean          5.058090    0.957449                      2.611685   746.893258  \n",
              "std           2.318286    0.228572                      0.709990   314.907474  \n",
              "min           1.280000    0.480000                      1.270000   278.000000  \n",
              "25%           3.220000    0.782500                      1.937500   500.500000  \n",
              "50%           4.690000    0.965000                      2.780000   673.500000  \n",
              "75%           6.200000    1.120000                      3.170000   985.000000  \n",
              "max          13.000000    1.710000                      4.000000  1680.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96279bff-61c2-4d4c-8375-e86ac25eac67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.000618</td>\n",
              "      <td>2.336348</td>\n",
              "      <td>2.366517</td>\n",
              "      <td>19.494944</td>\n",
              "      <td>99.741573</td>\n",
              "      <td>2.295112</td>\n",
              "      <td>2.029270</td>\n",
              "      <td>0.361854</td>\n",
              "      <td>1.590899</td>\n",
              "      <td>5.058090</td>\n",
              "      <td>0.957449</td>\n",
              "      <td>2.611685</td>\n",
              "      <td>746.893258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.811827</td>\n",
              "      <td>1.117146</td>\n",
              "      <td>0.274344</td>\n",
              "      <td>3.339564</td>\n",
              "      <td>14.282484</td>\n",
              "      <td>0.625851</td>\n",
              "      <td>0.998859</td>\n",
              "      <td>0.124453</td>\n",
              "      <td>0.572359</td>\n",
              "      <td>2.318286</td>\n",
              "      <td>0.228572</td>\n",
              "      <td>0.709990</td>\n",
              "      <td>314.907474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>11.030000</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>278.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.362500</td>\n",
              "      <td>1.602500</td>\n",
              "      <td>2.210000</td>\n",
              "      <td>17.200000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>1.742500</td>\n",
              "      <td>1.205000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>3.220000</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>1.937500</td>\n",
              "      <td>500.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.050000</td>\n",
              "      <td>1.865000</td>\n",
              "      <td>2.360000</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>2.355000</td>\n",
              "      <td>2.135000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>1.555000</td>\n",
              "      <td>4.690000</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>2.780000</td>\n",
              "      <td>673.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13.677500</td>\n",
              "      <td>3.082500</td>\n",
              "      <td>2.557500</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>2.875000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.950000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.120000</td>\n",
              "      <td>3.170000</td>\n",
              "      <td>985.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.830000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.230000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>3.880000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>3.580000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1680.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96279bff-61c2-4d4c-8375-e86ac25eac67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96279bff-61c2-4d4c-8375-e86ac25eac67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96279bff-61c2-4d4c-8375-e86ac25eac67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the Dataset\n",
        "wineDf.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmSCFXj_PEoz",
        "outputId": "e5fe6812-fe25-4a02-add1-d200f6fe7285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 178 entries, 0 to 177\n",
            "Data columns (total 13 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   alcohol                       178 non-null    float64\n",
            " 1   malic_acid                    178 non-null    float64\n",
            " 2   ash                           178 non-null    float64\n",
            " 3   alcalinity_of_ash             178 non-null    float64\n",
            " 4   magnesium                     178 non-null    float64\n",
            " 5   total_phenols                 178 non-null    float64\n",
            " 6   flavanoids                    178 non-null    float64\n",
            " 7   nonflavanoid_phenols          178 non-null    float64\n",
            " 8   proanthocyanins               178 non-null    float64\n",
            " 9   color_intensity               178 non-null    float64\n",
            " 10  hue                           178 non-null    float64\n",
            " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
            " 12  proline                       178 non-null    float64\n",
            "dtypes: float64(13)\n",
            "memory usage: 18.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleanig the dataset\n",
        "# remaning the od280/od315_of_diluted_wines  to diluted_wines\n",
        "wineDf = wineDf.rename(columns={'od280/od315_of_diluted_wines': 'of diluted_wines'})\n",
        "wineDf.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhHFNIOKPhm0",
        "outputId": "5e6773dc-6ab2-41d5-d100-a7bd3819b174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 178 entries, 0 to 177\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   alcohol               178 non-null    float64\n",
            " 1   malic_acid            178 non-null    float64\n",
            " 2   ash                   178 non-null    float64\n",
            " 3   alcalinity_of_ash     178 non-null    float64\n",
            " 4   magnesium             178 non-null    float64\n",
            " 5   total_phenols         178 non-null    float64\n",
            " 6   flavanoids            178 non-null    float64\n",
            " 7   nonflavanoid_phenols  178 non-null    float64\n",
            " 8   proanthocyanins       178 non-null    float64\n",
            " 9   color_intensity       178 non-null    float64\n",
            " 10  hue                   178 non-null    float64\n",
            " 11  % of diluted_wines    178 non-null    float64\n",
            " 12  proline               178 non-null    float64\n",
            "dtypes: float64(13)\n",
            "memory usage: 18.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7raihcRAQpd3",
        "outputId": "f79cce34-ea5d-4c34-b824-7d7511a9b54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=wine['target']\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-lW6UsnWE6p",
        "outputId": "15ed6401-69d6-4a12-8fee-adb65dba535b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Divide the dataset into a training set and a test set. You may use the\n",
        "# function train_test_split. Use your birthday in the format DDMM as\n",
        "# random_state (omit leading zeros if any).\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Use your birthday as the random_state 22/06\n",
        "random_state = 2206\n",
        "X_train, X_test, y_train,y_test = train_test_split(wineDf.iloc[:,:-1],y, test_size=0.2, random_state=random_state)\n"
      ],
      "metadata": {
        "id": "eEBZE9cTQUOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLPClassifier()\n",
        "mlp.fit(X_train,y_train)\n",
        "y_pred=mlp.predict(X_test)"
      ],
      "metadata": {
        "id": "C5nddVLfY0kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-validation is a technique used to evaluate the performance of a machine learning model on a dataset. It involves dividing the dataset into k subsets, training the model on k-1 subsets, and evaluating the model on the remaining subset. This is repeated for each subset, so that each subset is used as the test set exactly once. The average performance across all k iterations is used as the overall performance of the model.\n",
        "\n",
        "The cross_val_score function in scikit-learn is a convenient function for performing cross-validation. It takes as input the model to be evaluated, the training data, and the number of folds (k) to use in the cross-validation procedure. The function returns an array of scores, one for each iteration of the cross-validation.\n",
        "\n",
        "To use the cross_val_score function to estimate the generalization accuracy of the MLPClassifier with the default values of the parameters, you would do the following:\n",
        "\n",
        "\n",
        "\n",
        "# Create the MLPClassifier object\n",
        "mlp = MLPClassifier()\n",
        "\n",
        "# Use cross_val_score to evaluate the model\n",
        "scores = cross_val_score(mlp, X, y, cv=10)\n",
        "\n",
        "# Print the mean and standard deviation of the scores\n",
        "print(\"Mean accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "This will compute the mean and standard deviation of the cross-validation scores, which can be used as an estimate of the generalization accuracy of the MLPClassifier model.\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "\n",
        "# Create the MLPClassifier object\n",
        "mlp = MLPClassifier()\n",
        "\n",
        "# Use cross_val_score to evaluate the model on the training set\n",
        "scores = cross_val_score(mlp, X_train, y_train, cv=10)\n",
        "\n",
        "# Print the mean and standard deviation of the scores\n",
        "print(\"Mean accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iAt1Fe1bbUaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using cross-validation and the training set only, estimate the \n",
        "# generalization accuracy of the MLPClassifier \n",
        "# with the default values of the parameters. \n",
        "# You may use the function cross_val_score.\n",
        "\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Create the MLPClassifier object\n",
        "mlp = MLPClassifier()\n",
        "\n",
        "# Use cross_val_score to evaluate the model on the training set\n",
        "scores = cross_val_score(mlp, X_train, y_train, cv=10)\n",
        "\n",
        "# Print the mean and standard deviation of the scores\n",
        "print(\"Mean accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTr3KMjlWQj4",
        "outputId": "aacd7ad9-65ad-48e2-a792-cbf469e4ef26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.75 (+/- 0.46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One parameter that can affect the model's performance is max_iter, which specifies the maximum number of iterations to run when training the model. Increasing the value of max_iter can sometimes improve the model's performance, but it can also increase the time it takes to train the model.\n",
        "\n",
        "If you are getting warnings when training an MLPClassifier model, you can try increasing the value of the max_iter parameter to see if it helps"
      ],
      "metadata": {
        "id": "5uOXlArNdLRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get rid of the warnings by varying a parameter, or parameters, such as\n",
        "# max_iter. Estimate the generalization accuracy of the MLPClassifier\n",
        "# with the modified values of the parameters. (If there are no warnings, the\n",
        "# modified values of the parameters may be identical to the default values.)\n",
        "\n",
        "\n",
        "# Create the MLPClassifier object with increased max_iter\n",
        "mlp = MLPClassifier(max_iter=1000)\n",
        "\n",
        "# Use cross_val_score to evaluate the model\n",
        "scores = cross_val_score(mlp, X_train, y_train, cv=10)\n",
        "\n",
        "# Print the mean and standard deviation of the scores\n",
        "print(\"Mean accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz734DqhdMeN",
        "outputId": "75e70dc3-2f7b-4fcd-cf00-5123bb6bf57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.65 (+/- 0.59)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "an MLPClassifier object with a max_iter value of 1000, and then uses the cross_val_score function to evaluate the model using 10-fold cross-validation. The mean and standard deviation of the cross-validation scores are then printed, which can be used as an estimate of the generalization accuracy of the model with the modified value of the max_iter parameter"
      ],
      "metadata": {
        "id": "NSYnbiDHe4A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the test error rate of the MLPClassifier with the modified values\n",
        "# of parameters, compare it with the estimate obtained in the previous task\n",
        "# (task 4) for the same values of parameters, and write your observations in\n",
        "# a markdown cell of your Jupyter notebook.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wU78hT-Re48e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate the test error rate of the MLPClassifier with the modified value of the max_iter parameter, you can use the test set that was created earlier using the train_test_split function. You can do this by fitting the model on the training set and then using the score method to evaluate the model on the test set."
      ],
      "metadata": {
        "id": "uxDB2JU_fMaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the MLPClassifier object with increased max_iter\n",
        "mlp = MLPClassifier(max_iter=1000)\n",
        "\n",
        "# Fit the model on the training set\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = mlp.score(X_test, y_test)\n",
        "\n",
        "# Print the test error rate\n",
        "test_error_rate = 1 - test_accuracy\n",
        "print(\"Test error rate: %0.2f\" % test_error_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RNPLCqkfNXb",
        "outputId": "ad5a7ec6-04a9-4529-8177-716f4cbf37f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test error rate: 0.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLPClassifier object with a max_iter value of 1000. The model is then fitted on the training set and evaluated on the test set using the score method, which returns the mean accuracy on the given test data and labels. The test error rate is then computed as 1 minus the mean accuracy, and printed.\n",
        "\n",
        "To compare the test error rate with the estimate of the generalization accuracy obtained from cross-validation, you can simply subtract the mean of the cross-validation scores from 1"
      ],
      "metadata": {
        "id": "95Lyx3iiflpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = mlp.predict(X_test)\n",
        "\n",
        "# Compute the error rate\n",
        "error_rate = 1 - accuracy_score(y_test, predictions)\n",
        "\n",
        "# Print the error rate\n",
        "print(\"Test error rate: %0.2f\" % error_rate)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnHR_EFjfyY7",
        "outputId": "0cd504a5-4c75-4367-cb35-16b789b9924c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test error rate: 0.06\n",
            "[2 2 2 2 0 2 2 2 0 1 0 1 2 2 1 0 0 2 1 0 1 1 0 1 1 1 0 1 1 2 1 1 1 2 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training set\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = mlp.score(X_test, y_test)\n",
        "\n",
        "# Print the test error rate\n",
        "test_error_rate = 1 - test_accuracy\n",
        "print(\"Test error rate: %0.2f\" % test_error_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE5-cm_EhbE2",
        "outputId": "f9a4b250-d9b8-4fc6-f098-84c763d2bcd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test error rate: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code makes predictions on the test set using the trained MLPClassifier model, and then computes the error rate by comparing the predicted labels with the true labels. The error rate is then printed.The test error rate will be slightly higher than the estimate obtained from cross-validation, since the cross-validation procedure uses multiple train/test splits to reduce the variance of the estimate.the training set, and then evaluates the model on the test set. It prints the test error rate, which can be compared with the estimate of the generalization accuracy obtained from cross-validation.It is generally expected that the test error rate will be slightly higher than the estimate of the generalization accuracy obtained from cross-validation, as the model has not been trained on the test set and therefore may not perform as well on unseen data. However, if the difference between the two is large, it may indicate that the model is overfitting to the training data and may not generalize well to new data"
      ],
      "metadata": {
        "id": "RoOuaQkzgtox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #  Create a pipeline for MLPClassifier involving data normalization and\n",
        "# MLPClassifier, and use grid search and cross-validation to tune parameter alpha for the pipeline, avoiding data snooping and data leakage. You\n",
        "# may use the scikit-learn class GridSearchCV. Experiment with different ways of doing normalization (such as StandardScaler, MinMaxScaler,\n",
        "# RobustScaler, and Normalizer)."
      ],
      "metadata": {
        "id": "0M-QtLFNgZhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
        "\n",
        "# Create a pipeline with StandardScaler normalization\n",
        "pipe_std = Pipeline([('scaler', StandardScaler()), ('mlp', MLPClassifier())])\n",
        "\n",
        "# Create a pipeline with MinMaxScaler normalization\n",
        "pipe_minmax = Pipeline([('scaler', MinMaxScaler()), ('mlp', MLPClassifier())])\n",
        "\n",
        "# Create a pipeline with RobustScaler normalization\n",
        "pipe_robust = Pipeline([('scaler', RobustScaler()), ('mlp', MLPClassifier())])\n",
        "\n",
        "# Create a pipeline with Normalizer normalization\n",
        "pipe_norm = Pipeline([('scaler', Normalizer()), ('mlp', MLPClassifier())])\n"
      ],
      "metadata": {
        "id": "eC2VY4BrihBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TtBoJ_a5jZjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates four pipelines, each with a different data normalization\n",
        " method (StandardScaler, MinMaxScaler, RobustScaler, or Normalizer) and an MLPClassifier model. \n",
        " The pipelines can be used to train the MLPClassifier model on normalized data.\n",
        "\n",
        "Once you have created a pipeline with data normalization, \n",
        "you can use grid search and cross-validation to tune the model's parameters, such as the alpha parameter of the MLPClassifier. \n",
        "This can help improve the model's performance by finding the best combination of parameter values for the data.\n",
        "\n",
        "To use grid search and cross-validation to tune the alpha parameter of the MLPClassifier in a pipeline, you can do the following:"
      ],
      "metadata": {
        "id": "KcZJknhEj0H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Set the parameters to search over\n",
        "param_grid = {'mlp__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
        "\n",
        "# Create a grid search object with 10-fold cross-validation\n",
        "grid_std = GridSearchCV(pipe_std, param_grid, cv=10)\n",
        "grid_minmax = GridSearchCV(pipe_minmax, param_grid, cv=10)\n",
        "grid_robust = GridSearchCV(pipe_robust, param_grid, cv=10)\n",
        "grid_norm = GridSearchCV(pipe_norm, param_grid, cv=10)\n",
        "\n",
        "# Fit the grid search object to the training data\n",
        "grid_std.fit(X_train, y_train)\n",
        "grid_minmax.fit(X_train, y_train)\n",
        "grid_robust.fit(X_train, y_train)\n",
        "grid_norm.fit(X_train, y_train)\n",
        "\n",
        "# Print the best score and best parameters for each normalization method\n",
        "# print(\"StandardScaler: %0.2f (+/- %0.2f) for %r\" % (grid_std.best_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUoJKLf0jfvP",
        "outputId": "e470f6ad-09e0-4a8a-e48e-d6fcfc8825ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10,\n",
              "             estimator=Pipeline(steps=[('scaler', Normalizer()),\n",
              "                                       ('mlp', MLPClassifier())]),\n",
              "             param_grid={'mlp__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Set the parameters to search over\n",
        "param_grid = {'mlp__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
        "\n",
        "# Create a grid search object with 10-fold cross-validation\n",
        "grid_std = GridSearchCV(pipe_std, param_grid, cv=10)\n",
        "grid_minmax = GridSearchCV(pipe_minmax, param_grid, cv=10)\n",
        "grid_robust = GridSearchCV(pipe_robust, param_grid, cv=10)\n",
        "grid_norm = GridSearchCV(pipe_norm, param_grid, cv=10)\n",
        "\n",
        "# Fit the grid search object to the training data\n",
        "grid_std.fit(X_train, y_train)\n",
        "grid_minmax.fit(X_train, y_train)\n",
        "grid_robust.fit(X_train, y_train)\n",
        "grid_norm.fit(X_train, y_train)\n",
        "\n",
        "# Print the best score and best parameters for each normalization method\n",
        "print(\"StandardScaler: %0.2f (+/- %0.2f) for %r\" % (grid_std.best_score_, grid_std.cv_results_['std_test_score'][grid_std.best_index_], grid_std.best_params_))\n",
        "print(\"MinMaxScaler: %0.2f (+/- %0.2f) for %r\" % (grid_minmax.best_score_, grid_minmax.cv_results_['std_test_score'][grid_minmax.best_index_], grid_minmax.best_params_))\n",
        "print(\"RobustScaler: %0.2f (+/- %0.2f) for %r\" % (grid_robust.best_score_, grid_robust.cv_results_['std_test_score'][grid_robust.best_index_], grid_robust.best_params_))\n",
        "print(\"Normalizer: %0.2f (+/- %0.2f) for %r\" % (grid_norm.best_score_, grid_norm.cv_results_['std_test_score'][grid_norm.best_index_],grid_norm.best_params_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du56CabKluuk",
        "outputId": "aeaae444-013e-42cb-e2d2-925d6c1fb032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StandardScaler: 0.98 (+/- 0.03) for {'mlp__alpha': 0.1}\n",
            "MinMaxScaler: 0.97 (+/- 0.06) for {'mlp__alpha': 0.1}\n",
            "RobustScaler: 0.97 (+/- 0.03) for {'mlp__alpha': 1.0}\n",
            "Normalizer: 0.63 (+/- 0.14) for {'mlp__alpha': 0.01}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the GridSearchCV object of task 6 to the training set and use it to\n",
        "# predict the test labels. Write the resulting test error rate in your Jupyter\n",
        "# notebook."
      ],
      "metadata": {
        "id": "Ir4wAqXumwUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fit the GridSearchCV object to the training data and use it to predict the test labels, you can use the fit and predict methods.\n"
      ],
      "metadata": {
        "id": "5zLX-WGLw0EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the grid search object to the training data\n",
        "grid_std.fit(X_train, y_train)\n",
        "\n",
        "# Use the fitted grid search object to predict the labels of the test set\n",
        "y_pred = grid_std.predict(X_test)\n"
      ],
      "metadata": {
        "id": "j_THv7HUw4SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "an calculate the test error rate by comparing the predicted labels to the true test labels and computing the average classification error. For example, you can use sklearn's accuracy_score function to compute the average classification accuracy:"
      ],
      "metadata": {
        "id": "K3NcHOW_x-MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average classification accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the test error rate\n",
        "print(\"Test error rate: \", 1 - accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w221YZb-xe6u",
        "outputId": "966738fd-20ca-4f81-f172-19f056bb43c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test error rate:  0.05555555555555558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvdWsw8SyYkB",
        "outputId": "ff669ff4-42a1-4d42-db67-89e28552875a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95         9\n",
            "           1       1.00      0.88      0.93        16\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.94      0.96      0.95        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a cross-conformal predictor. You may use the KFold class for\n",
        "# splitting into folds (start from 5 or 10 folds). For computing the conformity\n",
        "# scores for each fold, you may use one of the GridSearchCV objects that\n",
        "# you created in task 6 in combination with the predict_proba method "
      ],
      "metadata": {
        "id": "Uf2A4-HfylPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Set the number of folds\n",
        "k = 10\n",
        "\n",
        "# Split the data into k folds\n",
        "kf = KFold(n_splits=k)\n",
        "folds = kf.split(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "2qnODhs3zKW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MD2TGU5imzmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the folds\n",
        "for train_indices, test_indices in folds:\n",
        "    # Split the data into train and test sets\n",
        "    X_train_fold, X_test_fold = X_train[train_indices], X_train[test_indices]\n",
        "    y_train_fold, y_test_fold = y_train[train_indices], y_train[test_indices]\n",
        "    \n",
        "    # Fit the grid search object to the training data\n",
        "    grid.fit(X_train_fold, y_train_fold)\n",
        "    \n",
        "    # Use the fitted model to predict the class probabilities of the test data\n",
        "    y_proba = grid.predict_proba(X_test_fold)\n"
      ],
      "metadata": {
        "id": "q37xLO9b2Bvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the test samples in the fold\n",
        "for y, y_proba in zip(y_test_fold, y_proba):\n",
        "    # Compute the conformity score as the sum of the probabilities of the correct and\n"
      ],
      "metadata": {
        "id": "wT4HKg3f4VGI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}